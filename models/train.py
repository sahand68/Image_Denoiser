# -*- coding: utf-8 -*-
"""challenge2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Dnh00XNVBT5syeHMzFjwFiJ-Rn3kJ3x3
"""



from google.colab import drive
drive.mount('/content/gdrive/')

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import keras
from keras.layers import Activation, Dense, Input,BatchNormalization,MaxPooling2D, UpSampling2D, Conv2DTranspose
from keras.layers import Conv2D, Flatten
from keras.layers import Reshape, Conv2DTranspose
from keras.models import Model
from keras import backend as K
from keras.datasets import mnist
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import cv2
from os import listdir
from pylab import rcParams

images = list()
for filename in listdir('gdrive/My Drive/Data'):

    img_data = cv2.imread('gdrive/My Drive/Data/' + filename, )
    #print(img_data.shape)
    img_data =cv2.resize(img_data,(0,0),fx = 0.4, fy = 0.4)
    img_data = img_data[0:632, 0:152]
    newX,newY = img_data.shape[0],img_data.shape[1]

    #print(img_data.shape)
    img_gray =cv2.cvtColor(img_data, cv2.COLOR_BGR2GRAY)
    images.append(img_gray)


x_data= np.reshape(images[0:47], [-1,newX,newY, 1])

x_data = x_data.astype('float32') / 255

x_data_noisy= []
row,col,ch= x_data[0].shape
y_data=[]
x_data= x_data.tolist()

for i in range(47):
  x_copy = x_data[i].copy()
  for j in range(40):
    mean = 0
    sigma = 0.25*np.random.rand(1)
    gauss = np.random.normal(mean,sigma,(row,col,ch))
    noisy= x_copy + gauss
    x_data_noisy.append(noisy)
    y_data.append(x_copy)


y_data = np.asarray(y_data)
x_data_noisy = np.asarray(x_data_noisy)


x_data_noisy = np.clip(x_data_noisy, 0., 1.)
y_train =y_data[0:1600]
y_test = y_data[1600:]
x_train_noisy=  x_data_noisy[0:1600]
x_test_noisy = x_data_noisy[1600:]
x_test_noisy = np.clip(x_test_noisy, 0., 1.)

input_shape = ( newX,newY)
batch_size = 64
kernel_size = 3
input_img = Input(shape=(newX,newY, 1))

x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
x = MaxPooling2D((2, 2), padding='same')(x)
x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
encoded = MaxPooling2D((2, 2), padding='same')(x)

# at this point the representation is (7, 7, 32)

x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)
x =Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(x)
x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
x = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(x)
decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)

autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')

autoencoder.fit(x_train_noisy, y_train,
                epochs=100,
                batch_size=64,
                shuffle=True,
                validation_data=(x_test_noisy, y_test),
                )

x_decoded = autoencoder.predict(x_test_noisy)


rows, cols = 1, 1
num = rows * cols
imgs = np.concatenate([y_test[:num], x_test_noisy[:num], x_decoded[:num]])
imgs = imgs.reshape((rows * 3, cols, newX,newY))
imgs = np.vstack(np.split(imgs, rows, axis=1))
imgs = imgs.reshape((rows * 3, -1, newX,newY))
imgs = np.vstack([np.hstack(i) for i in imgs])
imgs = (imgs * 255).astype(np.uint8)
plt.figure()
plt.axis('off')
plt.title('Original images: top rows, '
          'Corrupted Input: middle rows, '
          'Denoised Input:  third rows')
plt.imshow(imgs, interpolation='none', cmap='gray')
rcParams['figure.figsize'] = 20, 30
Image.fromarray(imgs).save('corrupted_and_denoised.png')

plt.show()



model_json = autoencoder.to_json()

with open('gdrive/My Drive/Colab Notebooks/model.json','w') as json_file:
  json_file.write(model_json)

autoencoder.save('gdrive/My Drive/Colab Notebooks/model.h5')